---
layout: post
tagline:  ""
title: "Повышаем функциональность кластера KVM с помошью NAS"
date:   2014-10-15 11:56:56
category: posts
tags : [KVM,NAS]
wordpress_id : 1001
---

В данной заметке, я расскажу как небольшими затратами на покупку сетевого хранилища D-Link 320L исправить всплывшие косяки сделать 2-х узловой Proxmox кластер функциональнее и надёжнее : вернуть потерянную живую миграцию, съеденую пробросом в виртуалки USB-устройствами; добавить в fencing третье устройство; и перенести бэкапы и свякий мусор в nfs шару...

В одином из ныне здравствующих проектов, как-то назрел апгрейд железа: использовались обычные старенькие бытовые компы, и это для системы которая должна работать 24/7. Пару раз даже кое-что ломалось :( При маленьком бюджете, хотелось сделать "бо[ɦ](https://uk.wikipedia.org/wiki/%D0%94%D0%B7%D0%B2%D1%96%D0%BD%D0%BA%D0%B8%D0%B9_%D0%B3%D0%BE%D1%80%D1%82%D0%B0%D0%BD%D0%BD%D0%B8%D0%B9_%D1%84%D1%80%D0%B8%D0%BA%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D0%B8%D0%B9)ато". Я решил, что будет идеально перенести всю инфраструктуру на виртуалки. В итоге переноса, хотел получить стандартные блага цивилизации: 

+ независимость от железа;
+ живая миграция виртуалок между узлами;
+ создание бэкапов с рабочих систем;
+ что там ещё придумать и за уши притянуть, для важности?

Как это обычно бывает, ввиду первоначальных ограничений по финансам, пришлось реализовать всё это виртуальное "богатство" в виде двух`узлового кластера на базе KVM (Proxmox 3.1), без внешнего дискового хранилища, да и без нормального аппаратного рейда на взятых серверах. Всё пилилось на базе софтового линухового рейда (raid1 + hot spare) и репликации на базе DRBD с двумя выделенным у каждого сервера под бондинг сетевушками. Настройка всего этого чуда разговор отдельный -- оставлю на будующее. Ясно, что в данной реализации дисковая подсистема была самым слабым звеном, но имеющейся производительности хватило с головой. 

В процессе внедрения данного "изделия", стали явно видны косяки.

## Проблема
+ Живая миграция гостевых систем оказалась невозможна.

Упс, вот незадача -- в некоторые из гостей пробрасывались устройства COM и USB, а когда они проброшены, миграция он-лайн невозможна. А эта фича для меня была приоритетной. Понадобись провести профилактику, надо будет выключать виртуалку, в офф-лайне переносить её на другу ноду, и там пускать. Ах да, ещё главное незабыть устройства из USB-портов одного сервера переткуть в другие. А виртуалка должна 24/7 работать, я напомню. Грусть и уныние...

+ Создание бэкапов было или очень долгим по времени или подсаживало хранилище операциями чтения/записи.

Понятно, что бэкапы надо делать на отдельное устройство, желательно находящееся на растоянии превыщающем радиус поражения ЭМИ после ядерного взрыва. Но чего нет, того пока нет -- всё делалось на отдельный раздел всё тех же серверов. Запускаешь создание образа и получаешь мазохизм: не пропишешь скромные bwlimit и ionice для задачи, и наблюдаешь как СУБД в критичной виртуалке начинает тормозить и кашлять, пользователи матерятся. Если же ограничивать bwlimit и ionice, продолжительность процесса по времени уходит за второй десяток минут -- крайне долго.

+ Два сервера -- мало для организации HA-кластера

Строго говоря, никакого High Availability и так не планировалось. Но на будующее идея казалась интересной и проблем казалось мало. При двух физических серверах о кворуме говорить не приходится, кто кого первым убьёт тот и прав :) Нужно третьего собутыльника найти.


## Задача
Проблемы я вывел быстро, теперь нужно их разбить на конкретные задачи. Что я в принципе хотел сделать:

+ Ускорить резервное копирование виртуалок и разгрузить io дисков серверов KVM

+ Отказаться от проброса USB/COM, вернуть живую миграцию

+ Повысить отказоустойчивость HA-кластера

Из вышеперечисленных задач, на мой взгляд быстро вытекает логичное решение: нужно третье устройство, на которое мы будем писать бэкапы, уменьшая нагрузку на дисковую систему серверов. Это же устройство должно выполнять функцию USB-хаба и "третьего лишнего", который с кворумом поможет. 

Остаётся конкретизировать выше описанные измышления:

* Нужно организовать сетевое хранилище

Купим дешевенький NAS (на третий полноценный сервер денег то нет). Туда без проблем можно отваливать бэкапы виртуалок, бэкапы СУБД.. вообще любые бэкапы :) Использовать будем протокол nfs, его и Proxmox поддерживает, да и любой linux дистр.

* Необходимые виртуалкам USB-устройства пробрасывать по IP

Логичный вариант -- берём ещё одно устройство, в него втыкаем все наши USB и COM периферии, и раздаём на виртуалки по IP. Есть открытый проект usbip [который в последнем ядре 3.17 вошел в основную ветку]. Есть закрытые проекты, а-ля USB Redirector for Linux от incentives pro.

* Кворумный диск

HA-кластер рекомендуют делать из 3х узлов, что бы из бежать гонок за отключение в состоянии "Split-Brain". Но ~~отвага и слабоумие~~ кворумный диск позволяет делать кластеры и с двумя узлами, в надежде на лучше. Мы используем KVM, с ним в комплекте идёт демон qdiskd. По факту он периодически опрашивает общее блочное устройство которое подключается по iscsi протоколу на каждом узле, и по возможности чтения-записи определяется доступен ли ещё узел кластера или нет. [Тут](http://www.rhd.ru/docs/manuals/enterprise/RHEL-5-Manual/Cluster-Administration/s1-qdisk-considerations-CA.html) подробнее написано.

* Уменьшим размер образов виртуалок

Что греха таить, имея сетевое хранилище, туда и весь мусор с виртуалок скинуть можно. Файлы доступ к которым эпизодичен, и некритичен для функциональности с лёгкостью на NFS шары переносятся (в моём случае это были многочисленные wav файлики генерируемые Астериской). К тому-же, при создании виртуалок делался большой задел на будующее который себя не оправдал: диски резались по 64Г, а фактически на них занято было до 15G, и дальнейший рост не предвиделся (на серваке с СУБД, база за год неторопливо вырастает всего на 1G). А если убрать мусор, неиспользуемые пакеты, будет ещё меньше.

## Реализация
Приступим к приготовлению нашего сегодняшнего блюда.

### Сетевое хранилище

Из требований выходило, что нам нужно устройство поддерживющее: nfs, iscsi, usbip. Можно было взять старенький ПК-гробик, и всё это настроить. Но от ПК-гробиков я пытался уйти, и больше их в "серверной" не видеть. Рушил купить дешевый NAS -- дешево и компактно. Искать и надеяться, что кто-то уже выпустил сетевое хранилище в котором всё это реализовано можно до тепловой смерти вселенной: NFS и iscsi в бытовых дешевых NASах встретить ещё можно (Lenovo IX2) , а вот встроенного usbip я не видел. 
Великий гугл подсказал, что поставленного результата можно добиться меньшими деньгами -- взять такой девайс, который будет поддерживать запуск сторонних программ при загрузке, а точнее [fun_plug](http://nas-tweaks.net/) и всё нужное реализовать уже самому. В итоге был выбран D-Link DNS-320L. fun_plug на нём работает без проблем, к тому-же он был в ближайшем магазине :)

#### Установка и настройка fun_plug 
Документации на тему настройки fum_plug в интернете много. Хотя бы [тут](http://nas-tweaks.net/371/hdd-installation-of-the-fun_plug-0-7-on-nas-devices/) рукомендую почитать. 


#### nfs


#### iscsi

Правим /ffp/etc/iscsi/targets
~~~
extent0         /mnt/HD/HD_a2/storage/iscsi/target    0                 20M
lun0=iqn.my.com.domain:iscsi.disk1         rw      extent0                 0/0
~~~

#### Проброс USB по IP
Первоначально я попробовал использовать пакет открытый пакет [usbip](). Но с ним как то не сраслось: готовых пакетов не было для fun_plug не было, собрать из исходников не получилось (точнее не получилось собрать необходимые модули ядра). После безрезультатных попыток настроить это "безобразие", решил посмотреть коммерческий проект (USB Redirector for Linux](http://www.incentivespro.com/usb-server.html) от Incentives Pro. Лицензионные ограничения позволяют юзать данный продукт для прокидывания USB устройств между linux машинами без отчисления копеек разработчику, что и понравилось. Да и поставить пакет удалось меньшей кровью, так что сожалений никаких. 

В качестве подготовительного этапа нам понадобится установить набор пакетов, нужных для сборки модуля ядра:


Скачиваем дистр под нашу архитектуру http://www.incentivespro.com/usb-redirector-linux-arm-eabi.tar.gz


## Результаты
Теперь подведём итог тому чего удалось добиться